{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ins>__Stock News Sentiment Analysis Project__</ins>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TLDR: For a chosen stock, this function searches Yahoo Finance for the latest news and gets the latest sentiment (individual + overall) using a trained model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sentiment analysis project can be split into 3 sub-processes.\n",
    "\n",
    "<ins>1) Web Scraping (WebScraper class)</ins>\n",
    "\n",
    "For a particular stock, the function scrapes Yahoo Finance for news on that stock using Python's BeautifulSoup4 package. It first scrapes the webpage for all news article URLs relating to that stock and stores them into a list. Subsequently, the function scrapes each URL of its headline and body of text and stores them into another list.\n",
    "\n",
    "<ins>2) Training the sentiment analysis model (SentimentAnalyzer class)</ins>\n",
    "\n",
    "The sentiment analysis model was trained using the Maximum Entropy classification model from Python's NLTK and Gensim packages. In order to train the model, we curated 100 news articles from Yahoo Finance and manually categorized them into their overall sentiment towards a particular stock, consisting of 34 optimistic, 33 neutral, and 33 pessimistic articles. We then trained the classifier model based on these 100 curated labelled articles to recognize and classify new unseen news articles into these 3 categories. After training, the model was then saved using Python's pickle package.\n",
    "\n",
    "<ins>3) Combining the scraped articles and sentiment analysis model into a sentiment analysis application (StockSentimentApp class)</ins>\n",
    "\n",
    "The scraped articles and trained sentiment analysis model are combined and developed into a sentiment analysis application. The application takes in a ticker symbol as its input and outputs the sentiment of each scraped article. It does this by applying the trained classifier model on each news article stored in the corpus of scraped articles. The headline and hyperlink of each article is also shown in the output to enable the user to click and read each article if they are interested. Furthermore, the function summarises and outputs the overall sentiment towards the stock based on the count of each predicted sentiment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ins>Use Case</ins>\n",
    "\n",
    "From this application, users will be able to predict the expected overall sentiment of a particular stock in a relatively short amount of time based on the textual sentiment of financial experts. Users can then base their investment decision based on sound financial advice without spending hours skimming through financial news. Note, however, that this is meant to assist and not replace the human element of investing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ins>How to use</ins>\n",
    "\n",
    "Run all the cells below. When prompted, key in a stock name or ticker symbol (e.g. \"Amazon\" or \"AMZN\", the input is case insensitive). The function will then output a list of articles and their corresponding predicted sentiments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ins>DISCLAIMER</ins>\n",
    "\n",
    "The sentiment analysis model was trained based on the Maximum Entropy model, which is a probabilistic model that chooses the model with the highest entropy from a set of models that fit training data. It's based on the principle of maximum entropy and information theory. Because of this, certain articles that talk about multiple stocks or companies may result in inaccurate sentiment predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Installations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Web Scraping Installations\n",
    "# !pip install beautifulsoup4\n",
    "# !pip install requests\n",
    "\n",
    "# Sentiment Analysis Installations\n",
    "# !pip install nltk\n",
    "# !pip install gensim\n",
    "# !pip install contractions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Web Scraping Imports\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pickle\n",
    "\n",
    "# Sentiment Analysis Imports\n",
    "import nltk\n",
    "from nltk.util import ngrams\n",
    "import gensim\n",
    "import contractions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Web Scraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WebScraper:\n",
    "    def __init__(self, stock):\n",
    "        self.stock = stock.strip().upper()\n",
    "        self.headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/111.0.0.0 Safari/537.36'}\n",
    "        self.url = \"https://finance.yahoo.com/quote/\"\n",
    "        with open(\"name2ticker_dict.pkl\", \"rb\") as f:\n",
    "            self.name2ticker_dict = pickle.load(f)\n",
    "        self.stock_name = None\n",
    "        self.hyperlink_list = []\n",
    "        self.headline_list = []\n",
    "        self.article_list = []\n",
    "\n",
    "    def get_request(self, url_extension):\n",
    "        response = requests.get(self.url + url_extension + '/news/', headers=self.headers)\n",
    "        soup = BeautifulSoup(response.text, \"lxml\")\n",
    "        self.stock_name = soup.select_one('h1[class*=\"yf-\"]').text.strip()\n",
    "        self.hyperlink_list = [a[\"href\"] for a in soup.select('a[class*=\"subtle-link fin-size-small titles noUnderline\"]')][0:12]\n",
    "\n",
    "    def search_stock(self):\n",
    "        try:\n",
    "            self.get_request(self.stock)\n",
    "        except:\n",
    "            for name in self.name2ticker_dict:\n",
    "                if self.stock in name:\n",
    "                    self.get_request(self.name2ticker_dict[name])\n",
    "                    break\n",
    "        if self.stock_name == None:\n",
    "            raise ValueError(\"Stock does not exist!\")\n",
    "\n",
    "    def scrape_articles(self):\n",
    "        for hyperlink in self.hyperlink_list.copy():\n",
    "            try:\n",
    "                for component in hyperlink.split(\"/\"):\n",
    "                    if component == 'm': # removes articles with 'm' in the hyperlink because they indicate a redirected article\n",
    "                        raise ValueError\n",
    "                article = [] # each element in this list is a different paragraph\n",
    "                response = requests.get(hyperlink, headers=self.headers)\n",
    "                soup = BeautifulSoup(response.text, \"lxml\")\n",
    "                headline = soup.select_one('div[class*=\"cover-title\"]').text.strip() # returns headline if found but returns None otherwise\n",
    "                article.append(headline if headline[-1] in \".?!\" else headline + \".\")\n",
    "                for paragraph in soup.find_all(\"p\"):\n",
    "                    paragraph = paragraph.text.strip()\n",
    "                    if paragraph:\n",
    "                        article.append(paragraph if paragraph[-1] in \".?!\" else paragraph + \".\")\n",
    "                if len(article) <= 2: # if the number of elements scraped is less than or equal to 2, remove it because it likely indicates a premium or redirected article\n",
    "                    raise ValueError\n",
    "                self.headline_list.append(headline)\n",
    "                self.article_list.append(\" \".join(article)) # use the join method to join all the separated header and paragraphs into one long string\n",
    "            except: # remove cases where an article is locked behind a paywall or diverts the user to another news website\n",
    "                self.hyperlink_list.remove(hyperlink)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sentiment Analyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentAnalyzer:\n",
    "    def __init__(self):\n",
    "        with open(\"dictionary.pkl\", \"rb\") as f:\n",
    "            self.dictionary = pickle.load(f)\n",
    "        with open(\"maxent_sentiment_classifier.pkl\", \"rb\") as f:\n",
    "            self.classifier = pickle.load(f)\n",
    "        self.stop_list = nltk.corpus.stopwords.words('english')\n",
    "        self.lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "\n",
    "    def preprocess_text(self, text):\n",
    "        article = nltk.word_tokenize(text)\n",
    "        article = [w.lower() for w in article if w.isalnum() and w not in self.stop_list]\n",
    "        article = [self.lemmatizer.lemmatize(contractions.fix(w)) for w in article]\n",
    "        bigrams = [' '.join(w) for w in list(ngrams(article, 2))]\n",
    "        article.extend(bigrams)\n",
    "        return article\n",
    "\n",
    "    def predict_sentiment(self, text):\n",
    "        article = self.preprocess_text(text)\n",
    "        vector = self.dictionary.doc2bow(article)\n",
    "        article_as_dict = {id: 1 for (id, tf) in vector}\n",
    "        return self.classifier.classify(article_as_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stock Sentiment Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1)\tHeadline: Intel reports Q4 beats on top and bottom line, stock rises on foundry revenue outlook\n",
      "\tSentiment: Neutral\n",
      "\tArticle Link: https://finance.yahoo.com/news/intel-reports-q4-beats-on-top-and-bottom-line-stock-rises-on-foundry-revenue-outlook-181745845.html\n",
      "\n",
      "2)\tHeadline: Meta, Microsoft downplay DeepSeek threat\n",
      "\tSentiment: Neutral\n",
      "\tArticle Link: https://finance.yahoo.com/news/meta-microsoft-downplay-deepseek-threat-190639250.html\n",
      "\n",
      "3)\tHeadline: DeepSeek is AI's historic 'sub-four-minute mile' moment\n",
      "\tSentiment: Pessimistic\n",
      "\tArticle Link: https://finance.yahoo.com/video/deepseek-ais-historic-sub-four-154934344.html\n",
      "\n",
      "4)\tHeadline: Oracle debuts new AI agents as artificial intelligence war enters next battle\n",
      "\tSentiment: Optimistic\n",
      "\tArticle Link: https://finance.yahoo.com/news/oracle-debuts-new-ai-agents-as-artificial-intelligence-war-enters-next-battle-140057385.html\n",
      "\n",
      "5)\tHeadline: Over 25% of Warren Buffett's $300 Billion Portfolio Is Invested in These 4 Tech Stocks. Here's the Best of the Bunch.\n",
      "\tSentiment: Neutral\n",
      "\tArticle Link: https://finance.yahoo.com/news/over-25-warren-buffetts-300-095100043.html\n",
      "\n",
      "6)\tHeadline: Billionaire Philippe Laffont Just Sold Top Artificial Intelligence Stocks Nvidia and AMD and Piled Into 2 Players Dominating Another High-Growth Billion-Dollar Industry\n",
      "\tSentiment: Neutral\n",
      "\tArticle Link: https://finance.yahoo.com/news/billionaire-philippe-laffont-just-sold-093000355.html\n",
      "\n",
      "7)\tHeadline: Q4 2024 United Parcel Service Inc Earnings Call\n",
      "\tSentiment: Optimistic\n",
      "\tArticle Link: https://finance.yahoo.com/news/q4-2024-united-parcel-inc-071644649.html\n",
      "\n",
      "8)\tHeadline: Jim Cramer Says Amazon.com, Inc. (AMZN) Is ‘Levitating’\n",
      "\tSentiment: Optimistic\n",
      "\tArticle Link: https://finance.yahoo.com/news/jim-cramer-says-amazon-com-070941988.html\n",
      "\n",
      "9)\tHeadline: Veteran stock trader's latest Amazon move turns heads\n",
      "\tSentiment: Optimistic\n",
      "\tArticle Link: https://finance.yahoo.com/news/veteran-stock-traders-latest-amazon-010700823.html\n",
      "\n",
      "10)\tHeadline: S&P 500 Gains and Losses Today: UPS Stock Drops as Shipper Trims Amazon Deliveries\n",
      "\tSentiment: Optimistic\n",
      "\tArticle Link: https://finance.yahoo.com/news/p-500-gains-losses-today-214047548.html\n",
      "\n",
      "11)\tHeadline: Amazon.com, Inc. (AMZN): The Powerhouse of Ecommerce and Generative AI Innovations\n",
      "\tSentiment: Optimistic\n",
      "\tArticle Link: https://finance.yahoo.com/news/amazon-com-inc-amzn-powerhouse-211335673.html\n",
      "\n",
      "12)\tHeadline: Amazon reportedly boosts ad-spending on X in major U-turn: WSJ\n",
      "\tSentiment: Optimistic\n",
      "\tArticle Link: https://finance.yahoo.com/news/amazon-reportedly-boosts-ad-spending-211137653.html\n",
      "\n",
      "Summary:\n",
      "Optimistic: 7\tPessimistic: 1\tNeutral: 4\t\n",
      "The overall sentiment for Amazon.com, Inc. (AMZN) is optimistic.\n"
     ]
    }
   ],
   "source": [
    "class StockSentimentApp:\n",
    "    def __init__(self, stock):\n",
    "        self.stock = stock\n",
    "        self.scraper = WebScraper(stock)\n",
    "        self.analyzer = SentimentAnalyzer()\n",
    "        self.sentiment_count = {'optimistic': 0, 'pessimistic': 0, 'neutral': 0}\n",
    "\n",
    "    def run(self):\n",
    "        self.scraper.search_stock()\n",
    "        self.scraper.scrape_articles()\n",
    "\n",
    "        for (i, (headline, article, hyperlink)) in enumerate(zip(self.scraper.headline_list, self.scraper.article_list, self.scraper.hyperlink_list)):\n",
    "            sentiment = self.analyzer.predict_sentiment(article)\n",
    "            print(f\"{i+1})\\tHeadline: {headline}\")\n",
    "            print(f\"\\tSentiment: {sentiment}\")\n",
    "            print(f\"\\tArticle Link: {hyperlink}\\n\")\n",
    "            self.sentiment_count[sentiment.lower()] += 1\n",
    "\n",
    "        if sum(self.sentiment_count.values()) == 0:\n",
    "            print(f\"There are no available news articles for {self.scraper.stock_name} on Yahoo Finance. Please try again later.\")\n",
    "        else:\n",
    "            print(\"Summary:\")\n",
    "            for (sentiment, count) in self.sentiment_count.items():\n",
    "                print(f\"{sentiment.capitalize()}: {count}\\t\", end=\"\")\n",
    "\n",
    "            def get_overall_sentiment(sentiment_count):\n",
    "                if sentiment_count['optimistic'] == sentiment_count['pessimistic']:\n",
    "                    return 'neutral'\n",
    "                return max(sentiment_count, key=sentiment_count.get)\n",
    "\n",
    "            print(f\"\\nThe overall sentiment for {self.scraper.stock_name} is {get_overall_sentiment(self.sentiment_count)}.\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    stock = input(\"Enter a Stock: \")\n",
    "    app = StockSentimentApp(stock)\n",
    "    app.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
